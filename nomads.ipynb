{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81d382a0-b24b-490b-93e9-d228b95c66ae",
   "metadata": {},
   "source": [
    "https://nomads.ncep.noaa.gov/\n",
    "\n",
    "https://nomads.ncep.noaa.gov/pub/data/nccf/com/aqm/prod/cs.20230331/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b7b0b4-4146-4e96-bba8-a5e132d1bf6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "DOWNLOAD_DIR = Path(\"./downloads\")\n",
    "DOWNLOAD_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf993d94-0d8e-4340-9582-4b32954934e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://nomads.ncep.noaa.gov/pub/data/nccf/com/aqm/prod/cs.20230331\"\n",
    "\n",
    "markup = BeautifulSoup(requests.get(url).content, \"html5lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e73c476-0e9e-46ed-b919-e45670463702",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tags = markup.find_all(\"a\")\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08f1476-21df-44d9-8e47-d83b329e9a1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "links = [f\"{url}/{href}\" for tag in tags if (href := tag['href']).startswith('aqm')]\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96af3fcf-15d7-45c4-8687-d094f0eff16a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57fac48-07af-421f-b35c-9e0e40523ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrate_limiter import Duration, RequestRate, Limiter, SQLiteBucket\n",
    "\n",
    "\n",
    "# Thread and process safe I/O rate limiter\n",
    "limiter = Limiter(\n",
    "    RequestRate(1, Duration.SECOND),\n",
    "    RequestRate(60, Duration.MINUTE),\n",
    "    bucket_class=SQLiteBucket\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0a928a-7e0a-46bc-95b4-6af927ab662d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "thread_local = threading.local()\n",
    "\n",
    "# Multithreaded I/O\n",
    "def get_thread_local_requests_session():\n",
    "    try:\n",
    "        return thread_local.session\n",
    "    except AttributeError:\n",
    "        thread_local.session = requests.Session()\n",
    "        return thread_local.session\n",
    "\n",
    "\n",
    "def delete_thread_local_requests_session():\n",
    "    try:\n",
    "        thread_local.session.close()\n",
    "        del thread_local.session\n",
    "    except AttributeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba29c8f-036f-47f2-937b-93041862b3f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from requests import Response, RequestException, HTTPError\n",
    "\n",
    "def get_url(url: str, max_tries: int = 5, stream=False) -> Response:\n",
    "    \"\"\"\n",
    "    Try to get a URL, retry on HTTP exceptions\n",
    "    \"\"\"\n",
    "\n",
    "    session = get_thread_local_requests_session()\n",
    "\n",
    "    for i in range(max_tries):\n",
    "\n",
    "        time.sleep(i and 2**i)\n",
    "\n",
    "        try:\n",
    "            with limiter.ratelimit(\"NOMADS\", delay=True, max_delay=60):\n",
    "                response = session.get(url, stream=stream, timeout=(6.05, 30))\n",
    "                \n",
    "                # For this notebook\n",
    "                print(response.request.method, response.request.url)\n",
    "                print(response.status_code, response.reason)\n",
    "\n",
    "            if response.status_code == 302:\n",
    "                # Treat this like an error.\n",
    "                # NOMADS sometimes returns 302 but with no headers, no location to redirect.\n",
    "                # These empty 302 responses seem to go away after a 30-second cooldown.\n",
    "                time.sleep(30)\n",
    "                raise HTTPError(\"Unhandled 302\", response=response)\n",
    "\n",
    "            if response.ok:\n",
    "                return response\n",
    "\n",
    "            response.raise_for_status()\n",
    "\n",
    "        except (ConnectionError, RequestException) as exc:\n",
    "            # It looks like requests might be catching native ConnectionError exceptions and re-raising\n",
    "            # them as its own requests.exceptions.ConnectionError (unrelated).\n",
    "            # For that reason we're catching the generic RequestException,\n",
    "            # which covers both requests.exceptions.HTTPError and requests.exceptions.ConnectionError.\n",
    "            if i == max_tries-1:\n",
    "                raise\n",
    "\n",
    "            # Don't retry on (most) client errors\n",
    "            # NOMADS sometimes returns 404 for a valid url, so retry\n",
    "            try:\n",
    "                if exc.response.status_code < 500 and exc.response.status_code not in {302, 429, 404}:\n",
    "                    raise\n",
    "            except AttributeError:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e5a99d-b578-4d9c-b629-c1cf8f9383c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_file(path: Path, url: str) -> None:\n",
    "    # Outer retry loop for successful requests with incomplete downloads\n",
    "    for i in range(4):\n",
    "\n",
    "        time.sleep(i and 5**i)\n",
    "\n",
    "        with get_url(url, max_tries=6, stream=True) as response:\n",
    "            try:\n",
    "                expected_size = int(response.headers[\"Content-Length\"])\n",
    "\n",
    "                with path.open(mode=\"wb\") as f:\n",
    "                    shutil.copyfileobj(response.raw, f)  # https://stackoverflow.com/a/39217788/8793243\n",
    "\n",
    "                if path.stat().st_size == expected_size:\n",
    "                    \n",
    "                    # For this notebook\n",
    "                    print(f\"Done downloading {path}\")\n",
    "                    \n",
    "                    return\n",
    "\n",
    "            except (KeyError, ValueError, FileNotFoundError):\n",
    "                pass\n",
    "\n",
    "        # With these errors, a fresh connection might help\n",
    "        delete_thread_local_requests_session()\n",
    "\n",
    "    # Make sure we don't end with a partial file\n",
    "    path.unlink(missing_ok=True)\n",
    "\n",
    "    raise RuntimeError(f\"Unable to download {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777619ee-b540-461c-9738-fe0454259257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternate basic version\n",
    "def download_file(dest: str, url: str):\n",
    "    with requests.get(url, stream=True) as response:\n",
    "        with Path(dest).open(mode=\"wb\") as f:\n",
    "            shutil.copyfileobj(response.raw, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806c34bc-5adb-4fd8-af69-170c7ba79bc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Limited resources on mybinder\n",
    "MAX_THREADS = 1 if os.getenv('BINDER_LAUNCH_HOST') == 'https://mybinder.org/' else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21212446-15a1-4f5b-b371-f42d7e989e52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=MAX_THREADS) as executor:\n",
    "    for link in links:\n",
    "        print(f\"submitting job for {link}\")\n",
    "        \n",
    "        filename = link.rsplit('/', maxsplit=1)[1]\n",
    "        \n",
    "        executor.submit(download_file, DOWNLOAD_DIR / filename, link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a445f5-9303-4189-8ba1-b2ac8ece3f54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
